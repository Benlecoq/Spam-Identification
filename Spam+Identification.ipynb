{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam mail identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Go until jurong point, crazy.. Available only ...       0\n",
       "1                      Ok lar... Joking wif u oni...       0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...       1\n",
       "3  U dun say so early hor... U c already then say...       0\n",
       "4  Nah I don't think he goes to usf, he lives aro...       0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('spam.csv')\n",
    "\n",
    "# Create labels\n",
    "data['target'] = np.where(data['target']=='spam',1,0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Vectorizing & base Logistic Regression model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy: 96.70%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], \n",
    "                                                    data['target'], \n",
    "                                                   random_state=0)\n",
    "# Fit vectorizer\n",
    "vect = TfidfVectorizer().fit(X_train)\n",
    "\n",
    "# Vectorize text\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "# Initiate model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit vectorized text to model\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict test set\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "# Print prediction accuracy\n",
    "print('Base model accuracy: ' + \\\n",
    "      \"%.2f\" % (accuracy_score(y_test, predictions)*100)+\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average characters feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Characters in Spam: 138.8661311914324\n",
      "Average Characters in Ham: 71.02362694300518\n"
     ]
    }
   ],
   "source": [
    "# Function to count characters\n",
    "def charcount(string):\n",
    "    lenght = len(string)\n",
    "    return lenght\n",
    "\n",
    "# Apply function to text\n",
    "data['characters'] = data['text'].apply(charcount)\n",
    "\n",
    "# Print average characters for each label\n",
    "print(\"Average Characters in Spam: \" + str(data['characters'].loc[data['target'] == 1].mean()))\n",
    "print(\"Average Characters in Ham: \" + str(data['characters'].loc[data['target'] == 0].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average digits feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Digits in Spam: 15.759036144578314\n",
      "Average Digits in Ham: 0.2992746113989637\n"
     ]
    }
   ],
   "source": [
    "# Function to count digits\n",
    "def digitcount(string):\n",
    "    digitcount = 0\n",
    "    for c in string:\n",
    "        if c.isdigit():\n",
    "            digitcount=digitcount+1\n",
    "        else:\n",
    "            pass\n",
    "    return digitcount\n",
    "\n",
    "# Apply function to text\n",
    "data['digits'] = data['text'].apply(digitcount)\n",
    "\n",
    "# Print average digits for each label\n",
    "print(\"Average Digits in Spam: \" + str(data['digits'].loc[data['target'] == 1].mean()))\n",
    "print(\"Average Digits in Ham: \" + str(data['digits'].loc[data['target'] == 0].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average non-word characters feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average non-word Char. in Spam: 29.041499330655956\n",
      "Average non-word Char. in Ham: 17.29181347150259\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to count non-word characters\n",
    "def nwcharcount (string):\n",
    "    nonchar = re.sub('[\\w]+' ,'', string)\n",
    "    return len(nonchar)\n",
    "\n",
    "# Apply function to text\n",
    "data['nwchar'] = data['text'].apply(nwcharcount)\n",
    "\n",
    "# Print average non-word char. for each label\n",
    "print(\"Average non-word Char. in Spam: \" + str(data['nwchar'].loc[data['target'] == 1].mean()))\n",
    "print(\"Average non-word Char. in Ham: \" + str(data['nwchar'].loc[data['target'] == 0].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search Vectorizer and Model parameters via Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'lr']\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.991\n",
      "Best parameters set:\n",
      "\tlr__C: 100\n",
      "\ttfidf__analyzer: 'char'\n",
      "\ttfidf__min_df: 20\n",
      "\ttfidf__ngram_range: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression()),\n",
    "])\n",
    "\n",
    "# Set parameters to search\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1,3), (2,5)),\n",
    "    'tfidf__min_df': (5, 10, 20, 50),\n",
    "    'tfidf__analyzer': ('word','char','char_wb'),\n",
    "    'lr__C': (10,50,100),}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, \n",
    "                           verbose=1, scoring = \"accuracy\", \n",
    "                           refit=True, cv=5)\n",
    "\n",
    "# Print results of grid search\n",
    "print (\"Performing grid search...\")\n",
    "print (\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "grid_search.fit(data.text, data.target) \n",
    "print (\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print (\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print (\"\\t%s: %r\" % (param_name, best_parameters[param_name]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model accuracy: 99.05%\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# Initiate vectorizer with optimal parameters\n",
    "vect = TfidfVectorizer(min_df=50, ngram_range=(1,3), analyzer='char').fit(data.text)\n",
    "\n",
    "# Vectorize text\n",
    "text_vectorized = vect.transform(data.text)\n",
    "\n",
    "# Combine vectorized text and features\n",
    "X_map = hstack([text_vectorized,\\\n",
    "                csr_matrix(data.characters).T,\\\n",
    "                csr_matrix(data.digits).T,\\\n",
    "                csr_matrix(data.nwchar).T], 'csr')\n",
    "\n",
    "# Initiate model with optimal parameters\n",
    "model = LogisticRegression(C=100)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_map, data.target)\n",
    "\n",
    "# Accuracy score 10-fold cross-validated \n",
    "Score = (cross_validation.cross_val_score(model, X_map, data.target, cv=10, scoring = \"accuracy\").mean())*100\n",
    "\n",
    "# Print model accuracy\n",
    "print(\"Final model accuracy: \" + \"%.2f\" % Score +\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
